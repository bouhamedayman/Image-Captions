{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from torchvision.models.inception import inception_v3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "a=inception_v3(pretrained=True,progress=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "for x in a.named_parameters():\n",
    "    print (x[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conv2d_1a_3x3.conv.weight\n",
      "Conv2d_1a_3x3.bn.weight\n",
      "Conv2d_1a_3x3.bn.bias\n",
      "Conv2d_2a_3x3.conv.weight\n",
      "Conv2d_2a_3x3.bn.weight\n",
      "Conv2d_2a_3x3.bn.bias\n",
      "Conv2d_2b_3x3.conv.weight\n",
      "Conv2d_2b_3x3.bn.weight\n",
      "Conv2d_2b_3x3.bn.bias\n",
      "Conv2d_3b_1x1.conv.weight\n",
      "Conv2d_3b_1x1.bn.weight\n",
      "Conv2d_3b_1x1.bn.bias\n",
      "Conv2d_4a_3x3.conv.weight\n",
      "Conv2d_4a_3x3.bn.weight\n",
      "Conv2d_4a_3x3.bn.bias\n",
      "Mixed_5b.branch1x1.conv.weight\n",
      "Mixed_5b.branch1x1.bn.weight\n",
      "Mixed_5b.branch1x1.bn.bias\n",
      "Mixed_5b.branch5x5_1.conv.weight\n",
      "Mixed_5b.branch5x5_1.bn.weight\n",
      "Mixed_5b.branch5x5_1.bn.bias\n",
      "Mixed_5b.branch5x5_2.conv.weight\n",
      "Mixed_5b.branch5x5_2.bn.weight\n",
      "Mixed_5b.branch5x5_2.bn.bias\n",
      "Mixed_5b.branch3x3dbl_1.conv.weight\n",
      "Mixed_5b.branch3x3dbl_1.bn.weight\n",
      "Mixed_5b.branch3x3dbl_1.bn.bias\n",
      "Mixed_5b.branch3x3dbl_2.conv.weight\n",
      "Mixed_5b.branch3x3dbl_2.bn.weight\n",
      "Mixed_5b.branch3x3dbl_2.bn.bias\n",
      "Mixed_5b.branch3x3dbl_3.conv.weight\n",
      "Mixed_5b.branch3x3dbl_3.bn.weight\n",
      "Mixed_5b.branch3x3dbl_3.bn.bias\n",
      "Mixed_5b.branch_pool.conv.weight\n",
      "Mixed_5b.branch_pool.bn.weight\n",
      "Mixed_5b.branch_pool.bn.bias\n",
      "Mixed_5c.branch1x1.conv.weight\n",
      "Mixed_5c.branch1x1.bn.weight\n",
      "Mixed_5c.branch1x1.bn.bias\n",
      "Mixed_5c.branch5x5_1.conv.weight\n",
      "Mixed_5c.branch5x5_1.bn.weight\n",
      "Mixed_5c.branch5x5_1.bn.bias\n",
      "Mixed_5c.branch5x5_2.conv.weight\n",
      "Mixed_5c.branch5x5_2.bn.weight\n",
      "Mixed_5c.branch5x5_2.bn.bias\n",
      "Mixed_5c.branch3x3dbl_1.conv.weight\n",
      "Mixed_5c.branch3x3dbl_1.bn.weight\n",
      "Mixed_5c.branch3x3dbl_1.bn.bias\n",
      "Mixed_5c.branch3x3dbl_2.conv.weight\n",
      "Mixed_5c.branch3x3dbl_2.bn.weight\n",
      "Mixed_5c.branch3x3dbl_2.bn.bias\n",
      "Mixed_5c.branch3x3dbl_3.conv.weight\n",
      "Mixed_5c.branch3x3dbl_3.bn.weight\n",
      "Mixed_5c.branch3x3dbl_3.bn.bias\n",
      "Mixed_5c.branch_pool.conv.weight\n",
      "Mixed_5c.branch_pool.bn.weight\n",
      "Mixed_5c.branch_pool.bn.bias\n",
      "Mixed_5d.branch1x1.conv.weight\n",
      "Mixed_5d.branch1x1.bn.weight\n",
      "Mixed_5d.branch1x1.bn.bias\n",
      "Mixed_5d.branch5x5_1.conv.weight\n",
      "Mixed_5d.branch5x5_1.bn.weight\n",
      "Mixed_5d.branch5x5_1.bn.bias\n",
      "Mixed_5d.branch5x5_2.conv.weight\n",
      "Mixed_5d.branch5x5_2.bn.weight\n",
      "Mixed_5d.branch5x5_2.bn.bias\n",
      "Mixed_5d.branch3x3dbl_1.conv.weight\n",
      "Mixed_5d.branch3x3dbl_1.bn.weight\n",
      "Mixed_5d.branch3x3dbl_1.bn.bias\n",
      "Mixed_5d.branch3x3dbl_2.conv.weight\n",
      "Mixed_5d.branch3x3dbl_2.bn.weight\n",
      "Mixed_5d.branch3x3dbl_2.bn.bias\n",
      "Mixed_5d.branch3x3dbl_3.conv.weight\n",
      "Mixed_5d.branch3x3dbl_3.bn.weight\n",
      "Mixed_5d.branch3x3dbl_3.bn.bias\n",
      "Mixed_5d.branch_pool.conv.weight\n",
      "Mixed_5d.branch_pool.bn.weight\n",
      "Mixed_5d.branch_pool.bn.bias\n",
      "Mixed_6a.branch3x3.conv.weight\n",
      "Mixed_6a.branch3x3.bn.weight\n",
      "Mixed_6a.branch3x3.bn.bias\n",
      "Mixed_6a.branch3x3dbl_1.conv.weight\n",
      "Mixed_6a.branch3x3dbl_1.bn.weight\n",
      "Mixed_6a.branch3x3dbl_1.bn.bias\n",
      "Mixed_6a.branch3x3dbl_2.conv.weight\n",
      "Mixed_6a.branch3x3dbl_2.bn.weight\n",
      "Mixed_6a.branch3x3dbl_2.bn.bias\n",
      "Mixed_6a.branch3x3dbl_3.conv.weight\n",
      "Mixed_6a.branch3x3dbl_3.bn.weight\n",
      "Mixed_6a.branch3x3dbl_3.bn.bias\n",
      "Mixed_6b.branch1x1.conv.weight\n",
      "Mixed_6b.branch1x1.bn.weight\n",
      "Mixed_6b.branch1x1.bn.bias\n",
      "Mixed_6b.branch7x7_1.conv.weight\n",
      "Mixed_6b.branch7x7_1.bn.weight\n",
      "Mixed_6b.branch7x7_1.bn.bias\n",
      "Mixed_6b.branch7x7_2.conv.weight\n",
      "Mixed_6b.branch7x7_2.bn.weight\n",
      "Mixed_6b.branch7x7_2.bn.bias\n",
      "Mixed_6b.branch7x7_3.conv.weight\n",
      "Mixed_6b.branch7x7_3.bn.weight\n",
      "Mixed_6b.branch7x7_3.bn.bias\n",
      "Mixed_6b.branch7x7dbl_1.conv.weight\n",
      "Mixed_6b.branch7x7dbl_1.bn.weight\n",
      "Mixed_6b.branch7x7dbl_1.bn.bias\n",
      "Mixed_6b.branch7x7dbl_2.conv.weight\n",
      "Mixed_6b.branch7x7dbl_2.bn.weight\n",
      "Mixed_6b.branch7x7dbl_2.bn.bias\n",
      "Mixed_6b.branch7x7dbl_3.conv.weight\n",
      "Mixed_6b.branch7x7dbl_3.bn.weight\n",
      "Mixed_6b.branch7x7dbl_3.bn.bias\n",
      "Mixed_6b.branch7x7dbl_4.conv.weight\n",
      "Mixed_6b.branch7x7dbl_4.bn.weight\n",
      "Mixed_6b.branch7x7dbl_4.bn.bias\n",
      "Mixed_6b.branch7x7dbl_5.conv.weight\n",
      "Mixed_6b.branch7x7dbl_5.bn.weight\n",
      "Mixed_6b.branch7x7dbl_5.bn.bias\n",
      "Mixed_6b.branch_pool.conv.weight\n",
      "Mixed_6b.branch_pool.bn.weight\n",
      "Mixed_6b.branch_pool.bn.bias\n",
      "Mixed_6c.branch1x1.conv.weight\n",
      "Mixed_6c.branch1x1.bn.weight\n",
      "Mixed_6c.branch1x1.bn.bias\n",
      "Mixed_6c.branch7x7_1.conv.weight\n",
      "Mixed_6c.branch7x7_1.bn.weight\n",
      "Mixed_6c.branch7x7_1.bn.bias\n",
      "Mixed_6c.branch7x7_2.conv.weight\n",
      "Mixed_6c.branch7x7_2.bn.weight\n",
      "Mixed_6c.branch7x7_2.bn.bias\n",
      "Mixed_6c.branch7x7_3.conv.weight\n",
      "Mixed_6c.branch7x7_3.bn.weight\n",
      "Mixed_6c.branch7x7_3.bn.bias\n",
      "Mixed_6c.branch7x7dbl_1.conv.weight\n",
      "Mixed_6c.branch7x7dbl_1.bn.weight\n",
      "Mixed_6c.branch7x7dbl_1.bn.bias\n",
      "Mixed_6c.branch7x7dbl_2.conv.weight\n",
      "Mixed_6c.branch7x7dbl_2.bn.weight\n",
      "Mixed_6c.branch7x7dbl_2.bn.bias\n",
      "Mixed_6c.branch7x7dbl_3.conv.weight\n",
      "Mixed_6c.branch7x7dbl_3.bn.weight\n",
      "Mixed_6c.branch7x7dbl_3.bn.bias\n",
      "Mixed_6c.branch7x7dbl_4.conv.weight\n",
      "Mixed_6c.branch7x7dbl_4.bn.weight\n",
      "Mixed_6c.branch7x7dbl_4.bn.bias\n",
      "Mixed_6c.branch7x7dbl_5.conv.weight\n",
      "Mixed_6c.branch7x7dbl_5.bn.weight\n",
      "Mixed_6c.branch7x7dbl_5.bn.bias\n",
      "Mixed_6c.branch_pool.conv.weight\n",
      "Mixed_6c.branch_pool.bn.weight\n",
      "Mixed_6c.branch_pool.bn.bias\n",
      "Mixed_6d.branch1x1.conv.weight\n",
      "Mixed_6d.branch1x1.bn.weight\n",
      "Mixed_6d.branch1x1.bn.bias\n",
      "Mixed_6d.branch7x7_1.conv.weight\n",
      "Mixed_6d.branch7x7_1.bn.weight\n",
      "Mixed_6d.branch7x7_1.bn.bias\n",
      "Mixed_6d.branch7x7_2.conv.weight\n",
      "Mixed_6d.branch7x7_2.bn.weight\n",
      "Mixed_6d.branch7x7_2.bn.bias\n",
      "Mixed_6d.branch7x7_3.conv.weight\n",
      "Mixed_6d.branch7x7_3.bn.weight\n",
      "Mixed_6d.branch7x7_3.bn.bias\n",
      "Mixed_6d.branch7x7dbl_1.conv.weight\n",
      "Mixed_6d.branch7x7dbl_1.bn.weight\n",
      "Mixed_6d.branch7x7dbl_1.bn.bias\n",
      "Mixed_6d.branch7x7dbl_2.conv.weight\n",
      "Mixed_6d.branch7x7dbl_2.bn.weight\n",
      "Mixed_6d.branch7x7dbl_2.bn.bias\n",
      "Mixed_6d.branch7x7dbl_3.conv.weight\n",
      "Mixed_6d.branch7x7dbl_3.bn.weight\n",
      "Mixed_6d.branch7x7dbl_3.bn.bias\n",
      "Mixed_6d.branch7x7dbl_4.conv.weight\n",
      "Mixed_6d.branch7x7dbl_4.bn.weight\n",
      "Mixed_6d.branch7x7dbl_4.bn.bias\n",
      "Mixed_6d.branch7x7dbl_5.conv.weight\n",
      "Mixed_6d.branch7x7dbl_5.bn.weight\n",
      "Mixed_6d.branch7x7dbl_5.bn.bias\n",
      "Mixed_6d.branch_pool.conv.weight\n",
      "Mixed_6d.branch_pool.bn.weight\n",
      "Mixed_6d.branch_pool.bn.bias\n",
      "Mixed_6e.branch1x1.conv.weight\n",
      "Mixed_6e.branch1x1.bn.weight\n",
      "Mixed_6e.branch1x1.bn.bias\n",
      "Mixed_6e.branch7x7_1.conv.weight\n",
      "Mixed_6e.branch7x7_1.bn.weight\n",
      "Mixed_6e.branch7x7_1.bn.bias\n",
      "Mixed_6e.branch7x7_2.conv.weight\n",
      "Mixed_6e.branch7x7_2.bn.weight\n",
      "Mixed_6e.branch7x7_2.bn.bias\n",
      "Mixed_6e.branch7x7_3.conv.weight\n",
      "Mixed_6e.branch7x7_3.bn.weight\n",
      "Mixed_6e.branch7x7_3.bn.bias\n",
      "Mixed_6e.branch7x7dbl_1.conv.weight\n",
      "Mixed_6e.branch7x7dbl_1.bn.weight\n",
      "Mixed_6e.branch7x7dbl_1.bn.bias\n",
      "Mixed_6e.branch7x7dbl_2.conv.weight\n",
      "Mixed_6e.branch7x7dbl_2.bn.weight\n",
      "Mixed_6e.branch7x7dbl_2.bn.bias\n",
      "Mixed_6e.branch7x7dbl_3.conv.weight\n",
      "Mixed_6e.branch7x7dbl_3.bn.weight\n",
      "Mixed_6e.branch7x7dbl_3.bn.bias\n",
      "Mixed_6e.branch7x7dbl_4.conv.weight\n",
      "Mixed_6e.branch7x7dbl_4.bn.weight\n",
      "Mixed_6e.branch7x7dbl_4.bn.bias\n",
      "Mixed_6e.branch7x7dbl_5.conv.weight\n",
      "Mixed_6e.branch7x7dbl_5.bn.weight\n",
      "Mixed_6e.branch7x7dbl_5.bn.bias\n",
      "Mixed_6e.branch_pool.conv.weight\n",
      "Mixed_6e.branch_pool.bn.weight\n",
      "Mixed_6e.branch_pool.bn.bias\n",
      "AuxLogits.conv0.conv.weight\n",
      "AuxLogits.conv0.bn.weight\n",
      "AuxLogits.conv0.bn.bias\n",
      "AuxLogits.conv1.conv.weight\n",
      "AuxLogits.conv1.bn.weight\n",
      "AuxLogits.conv1.bn.bias\n",
      "AuxLogits.fc.weight\n",
      "AuxLogits.fc.bias\n",
      "Mixed_7a.branch3x3_1.conv.weight\n",
      "Mixed_7a.branch3x3_1.bn.weight\n",
      "Mixed_7a.branch3x3_1.bn.bias\n",
      "Mixed_7a.branch3x3_2.conv.weight\n",
      "Mixed_7a.branch3x3_2.bn.weight\n",
      "Mixed_7a.branch3x3_2.bn.bias\n",
      "Mixed_7a.branch7x7x3_1.conv.weight\n",
      "Mixed_7a.branch7x7x3_1.bn.weight\n",
      "Mixed_7a.branch7x7x3_1.bn.bias\n",
      "Mixed_7a.branch7x7x3_2.conv.weight\n",
      "Mixed_7a.branch7x7x3_2.bn.weight\n",
      "Mixed_7a.branch7x7x3_2.bn.bias\n",
      "Mixed_7a.branch7x7x3_3.conv.weight\n",
      "Mixed_7a.branch7x7x3_3.bn.weight\n",
      "Mixed_7a.branch7x7x3_3.bn.bias\n",
      "Mixed_7a.branch7x7x3_4.conv.weight\n",
      "Mixed_7a.branch7x7x3_4.bn.weight\n",
      "Mixed_7a.branch7x7x3_4.bn.bias\n",
      "Mixed_7b.branch1x1.conv.weight\n",
      "Mixed_7b.branch1x1.bn.weight\n",
      "Mixed_7b.branch1x1.bn.bias\n",
      "Mixed_7b.branch3x3_1.conv.weight\n",
      "Mixed_7b.branch3x3_1.bn.weight\n",
      "Mixed_7b.branch3x3_1.bn.bias\n",
      "Mixed_7b.branch3x3_2a.conv.weight\n",
      "Mixed_7b.branch3x3_2a.bn.weight\n",
      "Mixed_7b.branch3x3_2a.bn.bias\n",
      "Mixed_7b.branch3x3_2b.conv.weight\n",
      "Mixed_7b.branch3x3_2b.bn.weight\n",
      "Mixed_7b.branch3x3_2b.bn.bias\n",
      "Mixed_7b.branch3x3dbl_1.conv.weight\n",
      "Mixed_7b.branch3x3dbl_1.bn.weight\n",
      "Mixed_7b.branch3x3dbl_1.bn.bias\n",
      "Mixed_7b.branch3x3dbl_2.conv.weight\n",
      "Mixed_7b.branch3x3dbl_2.bn.weight\n",
      "Mixed_7b.branch3x3dbl_2.bn.bias\n",
      "Mixed_7b.branch3x3dbl_3a.conv.weight\n",
      "Mixed_7b.branch3x3dbl_3a.bn.weight\n",
      "Mixed_7b.branch3x3dbl_3a.bn.bias\n",
      "Mixed_7b.branch3x3dbl_3b.conv.weight\n",
      "Mixed_7b.branch3x3dbl_3b.bn.weight\n",
      "Mixed_7b.branch3x3dbl_3b.bn.bias\n",
      "Mixed_7b.branch_pool.conv.weight\n",
      "Mixed_7b.branch_pool.bn.weight\n",
      "Mixed_7b.branch_pool.bn.bias\n",
      "Mixed_7c.branch1x1.conv.weight\n",
      "Mixed_7c.branch1x1.bn.weight\n",
      "Mixed_7c.branch1x1.bn.bias\n",
      "Mixed_7c.branch3x3_1.conv.weight\n",
      "Mixed_7c.branch3x3_1.bn.weight\n",
      "Mixed_7c.branch3x3_1.bn.bias\n",
      "Mixed_7c.branch3x3_2a.conv.weight\n",
      "Mixed_7c.branch3x3_2a.bn.weight\n",
      "Mixed_7c.branch3x3_2a.bn.bias\n",
      "Mixed_7c.branch3x3_2b.conv.weight\n",
      "Mixed_7c.branch3x3_2b.bn.weight\n",
      "Mixed_7c.branch3x3_2b.bn.bias\n",
      "Mixed_7c.branch3x3dbl_1.conv.weight\n",
      "Mixed_7c.branch3x3dbl_1.bn.weight\n",
      "Mixed_7c.branch3x3dbl_1.bn.bias\n",
      "Mixed_7c.branch3x3dbl_2.conv.weight\n",
      "Mixed_7c.branch3x3dbl_2.bn.weight\n",
      "Mixed_7c.branch3x3dbl_2.bn.bias\n",
      "Mixed_7c.branch3x3dbl_3a.conv.weight\n",
      "Mixed_7c.branch3x3dbl_3a.bn.weight\n",
      "Mixed_7c.branch3x3dbl_3a.bn.bias\n",
      "Mixed_7c.branch3x3dbl_3b.conv.weight\n",
      "Mixed_7c.branch3x3dbl_3b.bn.weight\n",
      "Mixed_7c.branch3x3dbl_3b.bn.bias\n",
      "Mixed_7c.branch_pool.conv.weight\n",
      "Mixed_7c.branch_pool.bn.weight\n",
      "Mixed_7c.branch_pool.bn.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import torch\n",
    "b=a(torch.rand((2,3,299,299)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "InceptionOutputs(logits=tensor([[-0.8174, -0.9727, -0.5494,  ...,  0.0837, -0.4448, -0.2338],\n",
       "        [ 0.6295, -0.0792,  0.3624,  ...,  0.2422,  0.6421,  0.0571]],\n",
       "       grad_fn=<AddmmBackward>), aux_logits=tensor([[-0.4393,  0.1509, -0.1480,  ...,  1.2503, -0.2540, -1.3491],\n",
       "        [ 0.3088, -0.7539, -0.3208,  ..., -1.1858,  0.3692,  1.2254]],\n",
       "       grad_fn=<AddmmBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "embed=nn.LSTM?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embed=nn.LSTM"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embed=nn.LSTM"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embed=nn.Embedding"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embed=nn.Embedding"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!ls"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:301310)",
      "at w.execute (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:300703)",
      "at w.start (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:296367)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:311160)",
      "at async t.CellExecutionQueue.start (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:310700)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "from Dataloader import get_loader,transform\n",
    "root_dir=os.path.join(os.getcwd(),'data/Flicker8k_Dataset')\n",
    "captions_file=os.path.join(os.getcwd(),\"data/captions.txt\")\n",
    "loader=get_loader(root_dir=root_dir,captions_file=captions_file,transform=transform)\n",
    "from tqdm import tqdm\n",
    "\"\"\"\"for idx,(image,caption) in enumerate(tqdm(loader,total=len(loader),leave=False)):\n",
    "    image=image.to(device='cuda')\n",
    "    caption=caption.to(device='cuda')\n",
    "    break    \"\"\" "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:301310)",
      "at w.execute (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:300703)",
      "at w.start (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:296367)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:311160)",
      "at async t.CellExecutionQueue.start (/home/ilmilanista/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:310700)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "for idx,(image,caption) in enumerate(tqdm(loader,leave=True,total=len(loader))):\n",
    "    print (image,caption)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10114 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in _pin_memory_loop\n    data = pin_memory(data)\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in pin_memory\n    return [pin_memory(sample) for sample in data]\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in <listcomp>\n    return [pin_memory(sample) for sample in data]\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 47, in pin_memory\n    return data.pin_memory()\nRuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/THCCachingHostAllocator.cpp:278\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-379e4c578c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in _pin_memory_loop\n    data = pin_memory(data)\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in pin_memory\n    return [pin_memory(sample) for sample in data]\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in <listcomp>\n    return [pin_memory(sample) for sample in data]\n  File \"/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 47, in pin_memory\n    return data.pin_memory()\nRuntimeError: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/THCCachingHostAllocator.cpp:278\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from Model import Encoder, Decoder\n",
    "essai1=Encoder(embed_size=20).to(device='cuda')\n",
    "essai2=Decoder(20,2994,20,1).to(device='cuda')\n",
    "c=essai1(image).to(device='cuda')\n",
    "b=essai2(c,caption[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "(b.reshape(-1, b.shape[2])).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([48, 2994])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "caption.reshape(6,8).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([6, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "criterion=nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "criterion((b.reshape(-1, b.shape[2])),caption.reshape(-1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(8.0278, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "torch"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/ilmilanista/anaconda3/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pytorch_lightning as pl \n",
    "pl.Trainer?"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlogger\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningLoggerBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningLoggerBase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdefault_root_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgradient_clip_algorithm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprocess_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_processes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mauto_select_gpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtpu_cores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlog_gpu_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moverfit_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrack_grad_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcheck_val_every_n_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfast_dev_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maccumulate_grad_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_train_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_val_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_test_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_predict_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mval_check_interval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mflush_logs_every_n_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlog_every_n_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maccelerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msync_batchnorm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprecision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mweights_summary\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'top'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mweights_save_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtruncated_bptt_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprofiler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofilers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProfiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbenchmark\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreload_dataloaders_every_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mauto_lr_find\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreplace_sampler_ddp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mterminate_on_nan\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mauto_scale_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprepare_data_per_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mplugins\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mamp_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'native'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mamp_level\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'O2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdistributed_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmove_metrics_to_cpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultiple_trainloader_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'max_size_cycle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstochastic_weight_avg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "TODO: Remove this class in v1.5.\n",
      "\n",
      "Use the utilities from ``pytorch_lightning.utilities.metrics`` instead.\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Customize every aspect of training via flags\n",
      "\n",
      "Args:\n",
      "\n",
      "    accelerator: Previously known as distributed_backend (dp, ddp, ddp2, etc...).\n",
      "        Can also take in an accelerator object for custom hardware.\n",
      "\n",
      "    accumulate_grad_batches: Accumulates grads every k batches or as set up in the dict.\n",
      "\n",
      "    amp_backend: The mixed precision backend to use (\"native\" or \"apex\")\n",
      "\n",
      "    amp_level: The optimization level to use (O1, O2, etc...).\n",
      "\n",
      "    auto_lr_find: If set to True, will make trainer.tune() run a learning rate finder,\n",
      "        trying to optimize initial learning for faster convergence. trainer.tune() method will\n",
      "        set the suggested learning rate in self.lr or self.learning_rate in the LightningModule.\n",
      "        To use a different key set a string instead of True with the key name.\n",
      "\n",
      "    auto_scale_batch_size: If set to True, will `initially` run a batch size\n",
      "        finder trying to find the largest batch size that fits into memory.\n",
      "        The result will be stored in self.batch_size in the LightningModule.\n",
      "        Additionally, can be set to either `power` that estimates the batch size through\n",
      "        a power search or `binsearch` that estimates the batch size through a binary search.\n",
      "\n",
      "    auto_select_gpus: If enabled and `gpus` is an integer, pick available\n",
      "        gpus automatically. This is especially useful when\n",
      "        GPUs are configured to be in \"exclusive mode\", such\n",
      "        that only one process at a time can access them.\n",
      "\n",
      "    benchmark: If true enables cudnn.benchmark.\n",
      "\n",
      "    callbacks: Add a callback or list of callbacks.\n",
      "\n",
      "    checkpoint_callback: If ``True``, enable checkpointing.\n",
      "        It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\n",
      "        :paramref:`~pytorch_lightning.trainer.trainer.Trainer.callbacks`.\n",
      "\n",
      "    check_val_every_n_epoch: Check val every n train epochs.\n",
      "\n",
      "    default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\n",
      "        Default: ``os.getcwd()``.\n",
      "        Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n",
      "\n",
      "    deterministic: If true enables cudnn.deterministic.\n",
      "\n",
      "    distributed_backend: deprecated. Please use 'accelerator'\n",
      "\n",
      "    fast_dev_run: runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\n",
      "        of train, val and test to find any bugs (ie: a sort of unit test).\n",
      "\n",
      "    flush_logs_every_n_steps: How often to flush logs to disk (defaults to every 100 steps).\n",
      "\n",
      "    gpus: number of gpus to train on (int) or which GPUs to train on (list or str) applied per node\n",
      "\n",
      "    gradient_clip_val: 0 means don't clip.\n",
      "\n",
      "    gradient_clip_algorithm: 'value' means clip_by_value, 'norm' means clip_by_norm. Default: 'norm'\n",
      "\n",
      "    limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches)\n",
      "\n",
      "    limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches)\n",
      "\n",
      "    limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches)\n",
      "\n",
      "    limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches)\n",
      "\n",
      "    logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\n",
      "        the default ``TensorBoardLogger``. ``False`` will disable logging.\n",
      "\n",
      "    log_gpu_memory: None, 'min_max', 'all'. Might slow performance\n",
      "\n",
      "    log_every_n_steps: How often to log within steps (defaults to every 50 steps).\n",
      "\n",
      "    prepare_data_per_node: If True, each LOCAL_RANK=0 will call prepare data.\n",
      "        Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare data\n",
      "\n",
      "    process_position: orders the progress bar when running multiple models on same machine.\n",
      "\n",
      "    progress_bar_refresh_rate: How often to refresh progress bar (in steps). Value ``0`` disables progress bar.\n",
      "        Ignored when a custom progress bar is passed to :paramref:`~Trainer.callbacks`. Default: None, means\n",
      "        a suitable value will be chosen based on the environment (terminal, Google COLAB, etc.).\n",
      "\n",
      "    profiler: To profile individual steps during training and assist in identifying bottlenecks.\n",
      "\n",
      "    overfit_batches: Overfit a fraction of training data (float) or a set number of batches (int).\n",
      "\n",
      "    plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\n",
      "\n",
      "    precision: Double precision (64), full precision (32) or half precision (16). Can be used on CPU, GPU or\n",
      "        TPUs.\n",
      "\n",
      "    max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\n",
      "        If both max_epochs and max_steps are not specified, defaults to ``max_epochs`` = 1000.\n",
      "\n",
      "    min_epochs: Force training for at least these many epochs. Disabled by default (None).\n",
      "        If both min_epochs and min_steps are not specified, defaults to ``min_epochs`` = 1.\n",
      "\n",
      "    max_steps: Stop training after this number of steps. Disabled by default (None).\n",
      "\n",
      "    min_steps: Force training for at least these number of steps. Disabled by default (None).\n",
      "\n",
      "    max_time: Stop training after this amount of time has passed. Disabled by default (None).\n",
      "        The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\n",
      "        :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\n",
      "        :class:`datetime.timedelta`.\n",
      "\n",
      "    num_nodes: number of GPU nodes for distributed training.\n",
      "\n",
      "    num_processes: number of processes for distributed training with distributed_backend=\"ddp_cpu\"\n",
      "\n",
      "    num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\n",
      "        Set it to `-1` to run all batches in all validation dataloaders.\n",
      "\n",
      "    reload_dataloaders_every_epoch: Set to True to reload dataloaders every epoch.\n",
      "\n",
      "    replace_sampler_ddp: Explicitly enables or disables sampler replacement. If not specified this\n",
      "        will toggled automatically when DDP is used. By default it will add ``shuffle=True`` for\n",
      "        train sampler and ``shuffle=False`` for val/test sampler. If you want to customize it,\n",
      "        you can set ``replace_sampler_ddp=False`` and add your own distributed sampler.\n",
      "\n",
      "    resume_from_checkpoint: Path/URL of the checkpoint from which training is resumed. If there is\n",
      "        no checkpoint file at the path, start from scratch. If resuming from mid-epoch checkpoint,\n",
      "        training will start from the beginning of the next epoch.\n",
      "\n",
      "    sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\n",
      "\n",
      "    terminate_on_nan: If set to True, will terminate training (by raising a `ValueError`) at the\n",
      "        end of each training batch, if any of the parameters or the loss are NaN or +/-inf.\n",
      "\n",
      "    tpu_cores: How many TPU cores to train on (1 or 8) / Single TPU to train on [1]\n",
      "\n",
      "    track_grad_norm: -1 no tracking. Otherwise tracks that p-norm. May be set to 'inf' infinity-norm.\n",
      "\n",
      "    truncated_bptt_steps: Deprecated in v1.3 to be removed in 1.5.\n",
      "        Please use :paramref:`~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps` instead.\n",
      "\n",
      "    val_check_interval: How often to check the validation set. Use float to check within a training epoch,\n",
      "        use int to check every n steps (batches).\n",
      "\n",
      "    weights_summary: Prints a summary of the weights when training begins.\n",
      "\n",
      "    weights_save_path: Where to save weights if specified. Will override default_root_dir\n",
      "        for checkpoints only. Use this if for whatever reason you need the checkpoints\n",
      "        stored in a different place than the logs written in `default_root_dir`.\n",
      "        Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n",
      "        Defaults to `default_root_dir`.\n",
      "\n",
      "    move_metrics_to_cpu: Whether to force internal logged metrics to be moved to cpu.\n",
      "        This can save some gpu memory, but can make training slower. Use with attention.\n",
      "\n",
      "    multiple_trainloader_mode: How to loop over the datasets when there are multiple train loaders.\n",
      "        In 'max_size_cycle' mode, the trainer ends one epoch when the largest dataset is traversed,\n",
      "        and smaller datasets reload when running out of their data. In 'min_size' mode, all the datasets\n",
      "        reload when reaching the minimum length of datasets.\n",
      "\n",
      "    stochastic_weight_avg: Whether to use `Stochastic Weight Averaging (SWA)\n",
      "        <https://pytorch.org/blog/pytorch-1.6-now-includes-stochastic-weight-averaging/>_`\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from Model import RCNN\n",
    "model=RCNN(20,2994,20,1,train_cnn=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model.re"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "Tue Sep 21 21:30:44 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX110       Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P0    N/A /  N/A |   1997MiB /  2004MiB |     57%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1257      G   /usr/lib/xorg/Xorg                 20MiB |\n",
      "|    0   N/A  N/A      1762      G   /usr/lib/xorg/Xorg                 83MiB |\n",
      "|    0   N/A  N/A      1963      G   /usr/bin/gnome-shell               25MiB |\n",
      "|    0   N/A  N/A      2621      G   ...AAAAAAAAA= --shared-files        7MiB |\n",
      "|    0   N/A  N/A      6316      G   ...AAAAAAAAA= --shared-files       34MiB |\n",
      "|    0   N/A  N/A     10716      G   ...gAAAAAAAAA --shared-files        6MiB |\n",
      "|    0   N/A  N/A     19447      C   ...ista/anaconda3/bin/python     1508MiB |\n",
      "|    0   N/A  N/A     40519      G   ...AAAAAAAAA= --shared-files       14MiB |\n",
      "|    0   N/A  N/A     44049      C   ...ista/anaconda3/bin/python      279MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "03c445df25f0733864318dce5c73803fb5374a5a8aedca5c383c4679969cca61"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}